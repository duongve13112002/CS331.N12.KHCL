{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25240,"status":"ok","timestamp":1668177992904,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"},"user_tz":-420},"id":"6fjJNLMjwDxz","outputId":"c2d57ae1-0e48-497b-b86c-11a4a2a95629"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f6j_mIsHxCik","executionInfo":{"status":"ok","timestamp":1668178041730,"user_tz":-420,"elapsed":43139,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}},"outputId":"546b9c28-d98f-4c92-a8fa-aea6f486ca6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyngrok\n","  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n","\u001b[K     |████████████████████████████████| 745 kB 26.1 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok) (6.0)\n","Building wheels for collected packages: pyngrok\n","  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=19007 sha256=aef562dad6a14054efc4d2ca65f23ade436bb9eea0a37d4061577777bf5ad1d1\n","  Stored in directory: /root/.cache/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n","Successfully built pyngrok\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-5.1.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flask_ngrok\n","  Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (1.1.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask_ngrok) (2.23.0)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.1.0)\n","Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (2.11.3)\n","Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (7.1.2)\n","Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask_ngrok) (1.0.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask_ngrok) (2.0.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask_ngrok) (1.24.3)\n","Installing collected packages: flask-ngrok\n","Successfully installed flask-ngrok-0.0.25\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting face_recognition\n","  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n","Collecting face-recognition-models>=0.3.0\n","  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n","\u001b[K     |████████████████████████████████| 100.1 MB 24 kB/s \n","\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.24.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.21.6)\n","Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n","Building wheels for collected packages: face-recognition-models\n","  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=624f4a2f12a77dfa9e8fce03e41b3e53ca661c52013e7f6a9b9531f8f8ebb7f8\n","  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n","Successfully built face-recognition-models\n","Installing collected packages: face-recognition-models, face-recognition\n","Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n"]}],"source":["! pip install pyngrok\n","!pip install flask_ngrok\n","!pip3 install face_recognition"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVF0q726xGN6","executionInfo":{"status":"ok","timestamp":1668178051472,"user_tz":-420,"elapsed":975,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}},"outputId":"646fc07c-d253-40b3-ab00-c24a2c200a59"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/project local API\n","'Flask API.ipynb'   helpers   README.md\t\t static\n","'Flask app .py'     model     requirements.txt\t video.mp4\n"]}],"source":["%cd \"/content/drive/MyDrive/Colab Notebooks/project local API\"\n","!ls \n"]},{"cell_type":"markdown","metadata":{"id":"t2eOjpSDz3Q1"},"source":["#  Import libraries"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wc_gtWMHyhui","executionInfo":{"status":"ok","timestamp":1668178061258,"user_tz":-420,"elapsed":5517,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"outputs":[],"source":["from flask import Flask, render_template, request, redirect, url_for\n","from keras.models import load_model\n","import numpy as np\n","import cv2\n","import os\n","from flask import Flask\n","from werkzeug.utils import secure_filename\n","import os\n","from tensorflow import keras\n","from flask import Flask, request, render_template\n","from werkzeug.utils import secure_filename\n","import dlib\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import img_to_array, load_img\n","from pyngrok import ngrok\n","from flask_ngrok import run_with_ngrok\n"]},{"cell_type":"markdown","metadata":{"id":"OIq5z1ECz0LV"},"source":["# Display Home Page "]},{"cell_type":"code","execution_count":5,"metadata":{"id":"v4aHMX8kyj3p","executionInfo":{"status":"ok","timestamp":1668178068586,"user_tz":-420,"elapsed":975,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"21272bc1-70e1-4720-c230-fe1ffb7d8625"},"outputs":[{"output_type":"stream","name":"stdout","text":[]}],"source":["app = Flask(__name__ , template_folder='static/templates')\n","ngrok.set_auth_token(\"29AhNyFJiBxEu0s07cR2zA8VqDQ_3wmwNStUSaHgpCiP2UNkd\")\n","run_with_ngrok(app)\n","@app.route('/')\n","def main():\n","  return render_template (\"Home.html\")"]},{"cell_type":"markdown","metadata":{"id":"_9LWfh85zvnR"},"source":["#  Redirect To Upload "]},{"cell_type":"code","execution_count":6,"metadata":{"id":"Sh85xq7JymhB","executionInfo":{"status":"ok","timestamp":1668178071321,"user_tz":-420,"elapsed":5,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"outputs":[],"source":["\n","\n","@app.route('/upload_video', methods=['POST'])\n","def Video():\n","  return render_template (\"Upload_Video.html\")\n","\n","@app.route('/upload_image', methods=['POST'])\n","def image():\n","    return render_template('Upload_image.html')\n","@app.route('/About-us', methods=['POST'])\n","def About_us():\n","  return render_template('About-us.html')\n"]},{"cell_type":"markdown","metadata":{"id":"i3e4WK4gzsIO"},"source":["# Load Model "]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Za9UHhU7yo6X","executionInfo":{"status":"ok","timestamp":1668178076124,"user_tz":-420,"elapsed":2856,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"outputs":[],"source":["import joblib\n","path = '/content/drive/MyDrive/Colab Notebooks/Experiments_DeepFakeDetection/finalized_model.sav'\n","model = joblib.load(path)\n","# model = tf.keras.models.load_model('/content/drive/MyDrive/Final project/Website/model/deepfake-detection-tensor.h5')"]},{"cell_type":"code","source":["import sys\n","import os\n","import torch\n","import cv2\n","import time\n","from torch import nn\n","import matplotlib.pyplot as plt\n","import matplotlib\n","from torchvision.transforms import Normalize\n","gpu = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n","gpu\n","\n","root = '/content/drive/MyDrive'\n","frames_per_video = 100\n","input_size = 224\n","test_val_frac = 0.3\n","\n","sys.path.insert(0, os.path.join(root, 'Colab Notebooks', 'blazeface-pytorch'))\n","sys.path.insert(0, os.path.join(root, 'Colab Notebooks'))\n","from blazeface import BlazeFace\n","facedet = BlazeFace().to(gpu)\n","\n","# Optionally change the thresholds:\n","facedet.min_score_thresh = 0.9\n","facedet.min_suppression_threshold = 0.9\n","\n","facedet.load_weights(os.path.join(root, 'Colab Notebooks', \"blazeface.pth\"))\n","facedet.load_anchors(os.path.join(root, 'Colab Notebooks', \"anchors.npy\"))\n","_ = facedet.train(False)\n","from helpers.read_video_1 import VideoReader\n","from helpers.face_extract_1 import FaceExtractor\n","\n","video_reader = VideoReader(verbose=True)\n","video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n","face_extractor = FaceExtractor(video_read_fn, facedet)"],"metadata":{"id":"zLPuxHAjpUes","executionInfo":{"status":"ok","timestamp":1668180007005,"user_tz":-420,"elapsed":407,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# from https://www.astrobetter.com/blog/2010/03/03/fourier-transforms-of-images-in-python/\n","import numpy as np\n","\n","def azimuthalAverage(image, center=None):\n","    \"\"\"\n","    Calculate the azimuthally averaged radial profile.\n","\n","    image - The 2D image\n","    center - The [x,y] pixel coordinates used as the center. The default is \n","             None, which then uses the center of the image (including \n","             fracitonal pixels).\n","    \n","    \"\"\"\n","    # Calculate the indices from the image\n","    y, x = np.indices(image.shape)\n","\n","    if not center:\n","        center = np.array([(x.max()-x.min())/2.0, (y.max()-y.min())/2.0])\n","\n","    r = np.hypot(x - center[0], y - center[1])\n","\n","    # Get sorted radii\n","    ind = np.argsort(r.flat)\n","    r_sorted = r.flat[ind]\n","    i_sorted = image.flat[ind]\n","\n","    # Get the integer part of the radii (bin size = 1)\n","    r_int = r_sorted.astype(int)\n","\n","    # Find all pixels that fall within each radial bin.\n","    deltar = r_int[1:] - r_int[:-1]  # Assumes all radii represented\n","    rind = np.where(deltar)[0]       # location of changed radius\n","    nr = rind[1:] - rind[:-1]        # number of radius bin\n","    \n","    # Cumulative sum to figure out sums for each radius bin\n","    csim = np.cumsum(i_sorted, dtype=float)\n","    tbin = csim[rind[1:]] - csim[rind[:-1]]\n","\n","    radial_prof = tbin / nr\n","\n","    return radial_prof"],"metadata":{"id":"tYdyvq5GqEcx","executionInfo":{"status":"ok","timestamp":1668180010926,"user_tz":-420,"elapsed":316,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o2OD7Uzkznx2"},"source":["# Function Prediction "]},{"cell_type":"code","execution_count":10,"metadata":{"id":"sbxbBnYYys_J","executionInfo":{"status":"ok","timestamp":1668178089953,"user_tz":-420,"elapsed":335,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"outputs":[],"source":["N = 500\n","from scipy.interpolate import griddata\n","def prediction_img (filepath):\n","  img = cv2.imread(filepath,0)\n","        \n","  # we crop the center\n","  h = int(img.shape[0]/3)\n","  w = int(img.shape[1]/3)\n","  img = img[h:-h,w:-w]\n","\n","  f = np.fft.fft2(img)\n","  fshift = np.fft.fftshift(f)\n","\n","  magnitude_spectrum = 20*np.log(np.abs(fshift))\n","  psd1D = azimuthalAverage(magnitude_spectrum)\n","\n","  # Calculate the azimuthally averaged 1D power spectrum\n","  points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n","  xi = np.linspace(0,N,num=N) # coordinates for interpolation\n","\n","  interpolated = griddata(points,psd1D,xi,method='cubic')\n","  interpolated /= interpolated[0]\n","  pre = model.predict([interpolated])\n","  if(pre == 1):\n","    return 'Real'\n","  else:\n","    return 'Fake'\n","\n","def prediction (filepath, rate =0.75):\n","  check = 0\n","  faces = face_extractor.process_video(filepath)\n","  face_extractor.keep_only_best_face(faces)\n","  if len(faces)>0:\n","      num=0\n","      for frame_data in faces:\n","          for img in frame_data['faces']:\n","\n","            img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","            h = int(img.shape[0]/3)\n","            w = int(img.shape[1]/3)\n","            img = img[h:-h,w:-w]\n","\n","            f = np.fft.fft2(img)\n","            fshift = np.fft.fftshift(f)\n","\n","            magnitude_spectrum = 20*np.log(np.abs(fshift))\n","            psd1D = azimuthalAverage(magnitude_spectrum)\n","\n","            # Calculate the azimuthally averaged 1D power spectrum\n","            points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n","            xi = np.linspace(0,N,num=N) # coordinates for interpolation\n","\n","            interpolated = griddata(points,psd1D,xi,method='cubic')\n","            interpolated /= interpolated[0]\n","            if(int(model.predict([interpolated]))):\n","              check +=1\n","            else: \n","              check -=1\n","  if(check <0):\n","    return('Fake')\n","  else:\n","    return(\"Real\")"]},{"cell_type":"markdown","metadata":{"id":"w6hz6MmqzhB-"},"source":["# Upload File"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"ddpM762aywCo","executionInfo":{"status":"ok","timestamp":1668178094243,"user_tz":-420,"elapsed":495,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"outputs":[],"source":["UPLOAD_FOLDER = 'static'\n","app.secret_key = \"secret key\"\n","app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n","app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024"]},{"cell_type":"markdown","metadata":{"id":"Z3egqPL9zVM2"},"source":["#  Video Prediction & Display Result "]},{"cell_type":"code","execution_count":12,"metadata":{"id":"5Xmm64H8yyk-","executionInfo":{"status":"ok","timestamp":1668178096107,"user_tz":-420,"elapsed":4,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"outputs":[],"source":["@app.route('/predict_video', methods=['POST'])\n","def upload_video():\n","\tfile = request.files['file']\n","\tfilename = secure_filename(file.filename)\n","\tfile.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n","\tfilepath = \"static/\"+filename\n","\tpreds = prediction(filepath)\n","\treturn render_template(\"Display_Video.html\",prediction =preds ,video_path = filename)"]},{"cell_type":"markdown","metadata":{"id":"vJ7JaIKezQyh"},"source":["# Image Prediction & Display Result "]},{"cell_type":"code","execution_count":13,"metadata":{"id":"89tk41__y4CX","executionInfo":{"status":"ok","timestamp":1668178098417,"user_tz":-420,"elapsed":564,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}}},"outputs":[],"source":["@app.route('/Predict_image', methods=['GET', 'POST'])\n","def upload():\n","    if request.method == 'POST':\n","        f = request.files['file']\n","        file_path = os.path.join (app.config['UPLOAD_FOLDER'], secure_filename(f.filename))\n","        f.save(file_path)\n","        # Make prediction\n","        preds = prediction_img(file_path)\n","    return render_template(\"Display_image.html\",prediction = preds, img_path= f.filename )\n"]},{"cell_type":"markdown","metadata":{"id":"0Up1IPIiy8VV"},"source":["# **Run Flask Application**#  "]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obt5rbWmwun2","executionInfo":{"status":"ok","timestamp":1668178369613,"user_tz":-420,"elapsed":269207,"user":{"displayName":"KHÁNH LÊ TRẦN QUỐC","userId":"05665848972952087032"}},"outputId":"45296258-9d19-4550-9922-8f4e41be7c28"},"outputs":[{"output_type":"stream","name":"stdout","text":[" * Serving Flask app \"__main__\" (lazy loading)\n"," * Environment: production\n","\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n","\u001b[2m   Use a production WSGI server instead.\u001b[0m\n"," * Debug mode: off\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug: * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"]},{"output_type":"stream","name":"stdout","text":[" * Running on http://1b2e-34-145-225-206.ngrok.io\n"," * Traffic stats available on http://127.0.0.1:4040\n"]},{"output_type":"stream","name":"stderr","text":["INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:26] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:27] \"\u001b[37mGET /static/css/main.css HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:27] \"\u001b[37mGET /static/css/normalize.css HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:28] \"\u001b[37mGET /static/background/deepfake2.jpeg HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:28] \"\u001b[37mGET /static/background/cover.mp4 HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:28] \"\u001b[37mGET /static/background/cover.mp4 HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:29] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:29] \"\u001b[37mGET /static/background/cover.mp4 HTTP/1.1\u001b[0m\" 206 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:29] \"\u001b[37mPOST /upload_video HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:30] \"\u001b[37mGET /static/js/jquery-1.12.4.min.js HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:30] \"\u001b[37mGET /static/js/main.js HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:31] \"\u001b[37mGET /static/css/aa.jpg HTTP/1.1\u001b[0m\" 200 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:48:43] \"\u001b[31m\u001b[1mPOST /predict_video HTTP/1.1\u001b[0m\" 413 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:52:01] \"\u001b[31m\u001b[1mPOST /predict_video HTTP/1.1\u001b[0m\" 413 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:52:21] \"\u001b[31m\u001b[1mPOST /predict_video HTTP/1.1\u001b[0m\" 413 -\n","INFO:werkzeug:127.0.0.1 - - [11/Nov/2022 14:52:25] \"\u001b[31m\u001b[1mPOST /predict_video HTTP/1.1\u001b[0m\" 413 -\n"]}],"source":["if __name__ =='__main__': \n","  app.run()"]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","video_PATH = \"/content/drive/MyDrive/Colab Notebooks/project local API/abc.mp4\"\n","check = 0\n","faces = face_extractor.process_video(video_PATH)\n","face_extractor.keep_only_best_face(faces)\n","print(len(faces))\n","if len(faces)>0:\n","    for frame_data in faces:\n","      # scores = frame_data['scores'].cpu().numpy()\n","      scores = np.array(frame_data['scores'])\n","      print('Scores: ', scores)\n","      if(len(scores) > 0):\n","        img = frame_data['faces'][np.where(scores == np.amax(scores))[0][0]]\n","        # for img in frame_data['faces']:\n","\n","        img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","        cv2_imshow(img)\n","        h = int(img.shape[0]/3)\n","        w = int(img.shape[1]/3)\n","        img = img[h:-h,w:-w]\n","\n","        f = np.fft.fft2(img)\n","        fshift = np.fft.fftshift(f)\n","\n","        magnitude_spectrum = 20*np.log(np.abs(fshift))\n","        psd1D = azimuthalAverage(magnitude_spectrum)\n","\n","        # Calculate the azimuthally averaged 1D power spectrum\n","        points = np.linspace(0,N,num=psd1D.size) # coordinates of a\n","        xi = np.linspace(0,N,num=N) # coordinates for interpolation\n","\n","        interpolated = griddata(points,psd1D,xi,method='cubic')\n","        interpolated /= interpolated[0]\n","\n","        pre = model.predict([interpolated])\n","        print(pre)\n","        if(int(pre)):\n","          check +=1\n","        else: check -=1\n","print(check)\n","if(check < 0):\n","  print('FAKE')\n","else:\n","  print(\"REAL\")"],"metadata":{"id":"YJt2MmlhLoCF"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}